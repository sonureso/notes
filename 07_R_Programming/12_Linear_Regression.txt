========================1. Linear Regression==============================
#format:  y = mx + c 
#if you think your data is almost linear, apply this.
#use following code to check...
--------------------------------------------------------------
# Create the predictor and response variable.
x <- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
y <- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
relation <- lm(y~x)
# Give the chart file a name.
png(file = "linearregression.png")
# Plot the chart.
plot(y,x,col = "blue",main = "Height & Weight Regression",cex = 1.3,pch = 16,xlab = "Weight in Kg",ylab = "Height in cm")
# Save the file.
dev.off()
--------------------------------------------------------------
========================2. Applying Linear Regression===================
	x <- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
	y <- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
	# Apply the lm() function.
	relation <- lm(y~x)
	print(relation)
o/p: (Intercept)            x  
          -38.4551       0.6746
#so you have now:   y = -38.4551 + 0.6746*x

========================2. Predictions====================================
1.	a <- data.frame(x = c(131,151,174,138))
	predict(relation,a)
	O/p: You will get corresponding predictions for y.

========================3. Making Line Graph=============================
# Create the predictor and response variable.
x <- c(151, 174, 138, 186, 128, 136, 179, 163, 152, 131)
y <- c(63, 81, 56, 91, 47, 57, 76, 72, 62, 48)
relation <- lm(y~x)
# Give the chart file a name.
png(file = "linearregression.png")
# Plot the chart.
plot(y,x,col = "blue",main = "Height & Weight Regression",
     abline(lm(x~y)),cex = 1.3,pch = 16,xlab = "Weight in Kg",ylab = "Height in cm")
# Save the file.
dev.off()

========================3. Analysis=======================================
# Use summary to get idea about it
	print(summary(relation)): Will print summary
	print(AIC(relation))    : Lower is better.
	print(AIC(relation))    : Lower is better.
#info: What is AIC and BIC?
	The Akaike’s information criterion – AIC (Akaike, 1974) and the Bayesian information criterion –
	 BIC (Schwarz, 1978) are measures of the goodness of fit of the linear regression model 
	and can also be used for model selection.
#Summary: The more the stars beside the variable’s p-Value, the more significant the variable.
	#--------Should be less than significance level 0.05
	#t-value: A larger t-value indicates that it is less likely that the coefficient is not equal 
	----------to zero purely by chance. So, higher the t-value, the better.
	STATISTIC	CRITERION
	R-Squared	Higher the better
	Adj R-Squared	Higher the better
	F-Statistic	Higher the better
	Std. Error	Closer to zero the better
	t-statistic	Should be greater 1.96 for p-value to be less than 0.05
	AIC	Lower the better
	BIC	Lower the better
	Mallows cp	Should be close to the number of predictors in model
	MAPE (Mean absolute percentage error)	Lower the better
	MSE (Mean squared error)	Lower the better
	Min_Max Accuracy => mean(min(actual, predicted)/max(actual, predicted))	Higher the better

